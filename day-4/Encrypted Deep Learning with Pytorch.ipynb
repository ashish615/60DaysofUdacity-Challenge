{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrypted Deep Learning in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy Dataset\n",
    "data = torch.tensor([[0,1], [0,1], [1,0], [1,1.]], requires_grad=True)\n",
    "targets = torch.tensor([[0], [0], [1], [1.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 20)\n",
    "        self.fc2 = nn.Linear(20, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7528)\n",
      "tensor(0.7895)\n",
      "tensor(0.4549)\n",
      "tensor(0.3149)\n",
      "tensor(0.2242)\n",
      "tensor(0.1644)\n",
      "tensor(0.1253)\n",
      "tensor(0.1017)\n",
      "tensor(0.0868)\n",
      "tensor(0.0768)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "for e in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(data)\n",
    "    loss = ((output - targets) ** 2).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0730],\n",
       "        [0.0730],\n",
       "        [1.1048],\n",
       "        [0.7815]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0630 19:19:10.989034 4638279104 hook.py:97] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0630 19:19:11.206663 4638279104 base.py:628] Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0630 19:19:11.208549 4638279104 base.py:628] Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0630 19:19:11.210836 4638279104 base.py:628] Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "bob = sy.VirtualWorker(hook, id='bob').add_worker(sy.local_worker)\n",
    "alice = sy.VirtualWorker(hook, id='alice').add_worker(sy.local_worker)\n",
    "secure_worker = sy.VirtualWorker(hook, id='sec_worker').add_worker(sy.local_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_model = model.fix_precision().share(bob, alice, crypto_provider=secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
       " \t-> (Wrapper)>[PointerTensor | me:285826575 -> bob:13012554282]\n",
       " \t-> (Wrapper)>[PointerTensor | me:39682574782 -> alice:48140103045]\n",
       " \t*crypto provider: sec_worker*, Parameter containing:\n",
       " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
       " \t-> (Wrapper)>[PointerTensor | me:20206922371 -> bob:72159487081]\n",
       " \t-> (Wrapper)>[PointerTensor | me:16360797443 -> alice:10638635001]\n",
       " \t*crypto provider: sec_worker*, Parameter containing:\n",
       " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
       " \t-> (Wrapper)>[PointerTensor | me:60564368515 -> bob:23879604697]\n",
       " \t-> (Wrapper)>[PointerTensor | me:54933155226 -> alice:67422394187]\n",
       " \t*crypto provider: sec_worker*, Parameter containing:\n",
       " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
       " \t-> (Wrapper)>[PointerTensor | me:88837381256 -> bob:36074538654]\n",
       " \t-> (Wrapper)>[PointerTensor | me:47105925163 -> alice:48642872749]\n",
       " \t*crypto provider: sec_worker*]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encrypted_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_data = data.fix_precision().share(bob, alice, crypto_provider=secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
       "\t-> (Wrapper)>[PointerTensor | me:36607840833 -> bob:60693690409]\n",
       "\t-> (Wrapper)>[PointerTensor | me:77198462042 -> alice:55980195832]\n",
       "\t*crypto provider: sec_worker*"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_prediction = encrypted_model(encrypted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted_prediction = encrypted_prediction.get().float_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0720],\n",
       "        [0.0720],\n",
       "        [1.1020],\n",
       "        [0.7790]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
